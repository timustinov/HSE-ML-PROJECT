{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "project-intro",
   "metadata": {},
   "source": [
    "# Анализ и прогнозирование потребления алкоголя студентами\n",
    "## Учебный исследовательский проект"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "project-goal",
   "metadata": {},
   "source": [
    "## 1. Цель работы\n",
    "\n",
    "Разработать модель машинного обучения для прогнозирования уровня потребления алкоголя студентами на основе их социально-демографических характеристик, академических показателей и семейных факторов. Задача имеет практическую значимость для образовательных учреждений и социальных служб в выявлении групп риска и разработке профилактических мер."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-description",
   "metadata": {},
   "source": [
    "## 2. Описание исходных данных\n",
    "\n",
    "**Источник данных:** Набор данных \"Student Alcohol Consumption\" с платформы HuggingFace Datasets\n",
    "\n",
    "**Структура данных:**\n",
    "- 395 наблюдений (студентов)\n",
    "- 33 признака, включая:\n",
    "  - Демографические: возраст, пол, тип семьи, размер семьи\n",
    "  - Социальные: время с друзьями, отношения с семьей, поддержка родителей\n",
    "  - Академические: оценки, посещаемость, дополнительные занятия\n",
    "  - Целевые переменные: потребление алкоголя в будни и выходные\n",
    "\n",
    "**Ключевые характеристики:**\n",
    "- Данные собраны в португальских школах\n",
    "- Содержит как числовые, так и категориальные признаки\n",
    "- Имеет некоторый дисбаланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Машинное обучение\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Модели\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Метрики\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report, roc_curve, precision_recall_curve, auc\n",
    ")\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Загружаем датасет\n",
    "dataset = load_dataset(\"scikit-learn/student-alcohol-consumption\")\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "print(f\"Размерность данных: {df.shape}\")\n",
    "print(f\"\\nКолонки: {list(df.columns)}\")\n",
    "print(f\"\\nТипы данных:\\n{df.dtypes.value_counts()}\")\n",
    "print(\"\\nПервые 5 строк:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предварительный анализ данных\n",
    "print(\"=== БАЗОВАЯ ИНФОРМАЦИЯ О ДАННЫХ ===\")\n",
    "print(f\"Всего наблюдений: {len(df)}\")\n",
    "print(f\"Всего признаков: {len(df.columns)}\")\n",
    "print(f\"\\nПропущенные значения:\\n{df.isnull().sum().sort_values(ascending=False).head(10)}\")\n",
    "\n",
    "print(\"\\n=== СТАТИСТИКА ПО ЦЕЛЕВЫМ ПЕРЕМЕННЫМ ===\")\n",
    "# Создаем бинарную целевую переменную: высокое потребление алкоголя\n",
    "# Объединяем потребление в будни и выходные\n",
    "df['total_alcohol'] = df['Dalc'] + df['Walc']  # Daily + Weekend alcohol\n",
    "df['high_alcohol'] = (df['total_alcohol'] >= 6).astype(int)  # Порог для высокого потребления\n",
    "\n",
    "print(f\"Распределение целевой переменной:\\n{df['high_alcohol'].value_counts()}\")\n",
    "print(f\"\\nПроцент студентов с высоким потреблением: {df['high_alcohol'].mean():.2%}\")\n",
    "\n",
    "# Визуализация распределения\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Распределение целевой переменной\n",
    "axes[0].bar(['Низкое', 'Высокое'], df['high_alcohol'].value_counts().sort_index())\n",
    "axes[0].set_title('Распределение уровня потребления алкоголя')\n",
    "axes[0].set_ylabel('Количество студентов')\n",
    "for i, v in enumerate(df['high_alcohol'].value_counts().sort_index()):\n",
    "    axes[0].text(i, v + 3, str(v), ha='center')\n",
    "\n",
    "# Распределение по полу\n",
    "gender_counts = df.groupby('sex')['high_alcohol'].mean()\n",
    "axes[1].bar(['Женщины', 'Мужчины'], [gender_counts['F'], gender_counts['M']])\n",
    "axes[1].set_title('Доля высокого потребления по полу')\n",
    "axes[1].set_ylabel('Доля')\n",
    "\n",
    "# Возрастное распределение\n",
    "age_alcohol = df.groupby('age')['high_alcohol'].mean()\n",
    "axes[2].plot(age_alcohol.index, age_alcohol.values, marker='o')\n",
    "axes[2].set_title('Зависимость потребления от возраста')\n",
    "axes[2].set_xlabel('Возраст')\n",
    "axes[2].set_ylabel('Доля высокого потребления')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных для моделирования\n",
    "# Выбираем наиболее релевантные признаки на основе предметной области\n",
    "selected_features = [\n",
    "    'age', 'sex', 'famsize', 'Pstatus', 'Medu', 'Fedu',  # Демографические и семейные\n",
    "    'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup',  # Академические\n",
    "    'paid', 'activities', 'higher', 'internet', 'romantic',  # Социальные\n",
    "    'famrel', 'freetime', 'goout', 'health', 'absences'  # Поведенческие без Walc и Dalc\n",
    "]\n",
    "\n",
    "# Создаем новый DataFrame с выбранными признаками\n",
    "X = df[selected_features].copy()\n",
    "y = df['high_alcohol'].values\n",
    "\n",
    "# Кодируем категориальные переменные\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "print(f\"Категориальные признаки: {list(categorical_cols)}\")\n",
    "print(f\"Числовые признаки: {list(numeric_cols)}\")\n",
    "\n",
    "# Применяем Label Encoding для категориальных признаков\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Разделение на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nРазмер тренировочной выборки: {X_train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape}\")\n",
    "print(f\"Баланс классов в трейне: {np.bincount(y_train)}\")\n",
    "print(f\"Баланс классов в тесте: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "algorithms",
   "metadata": {},
   "source": [
    "## 3. Используемые алгоритмы с обоснованием\n",
    "\n",
    "Для решения задачи бинарной классификации были выбраны следующие алгоритмы:\n",
    "\n",
    "1. **Логистическая регрессия** - базовый линейный метод, хорош для интерпретируемости и как бейзлайн\n",
    "2. **Random Forest** - ансамблевый метод, устойчив к переобучению, хорошо работает с категориальными признаками\n",
    "3. **Gradient Boosting** (XGBoost/LightGBM) - современный ансамблевый метод, часто показывает state-of-the-art результаты\n",
    "4. **Метод опорных векторов (SVM)** - эффективен в высокоразмерных пространствах\n",
    "5. **K-ближайших соседей (KNN)** - простой непараметрический метод для сравнения\n",
    "\n",
    "**Обоснование выбора:**\n",
    "- Набор данных небольшой (395 наблюдений), поэтому сложные глубокие модели нецелесообразны\n",
    "- Присутствуют как числовые, так и категориальные признаки\n",
    "- Имеется дисбаланс классов, что требует специальных подходов\n",
    "- Важна интерпретируемость результатов для практического применения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание и обучение моделей\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Масштабирование признаков\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Инициализация моделей\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100, class_weight='balanced'),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42, n_estimators=100),\n",
    "    'SVM': SVC(random_state=42, probability=True, class_weight='balanced'),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Обучение и оценка моделей\n",
    "results = {}\n",
    "predictions = {}\n",
    "probability_predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Обучение модели: {name}\")\n",
    "    \n",
    "    # Обучение модели\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Предсказания\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Сохранение результатов\n",
    "    predictions[name] = y_pred\n",
    "    probability_predictions[name] = y_pred_proba\n",
    "    \n",
    "    # Вычисление метрик\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_test, y_pred, zero_division=0),\n",
    "        'roc_auc': roc_auc_score(y_test, y_pred_proba)\n",
    "    }\n",
    "    \n",
    "    # Вывод метрик\n",
    "    print(f\"Accuracy: {results[name]['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results[name]['precision']:.4f}\")\n",
    "    print(f\"Recall: {results[name]['recall']:.4f}\")\n",
    "    print(f\"F1-Score: {results[name]['f1']:.4f}\")\n",
    "    print(f\"ROC-AUC: {results[name]['roc_auc']:.4f}\")\n",
    "    \n",
    "    # Матрица ошибок\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\nМатрица ошибок:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metrics",
   "metadata": {},
   "source": [
    "## 4. Как измерялось качество моделей\n",
    "\n",
    "Для оценки качества моделей использовались следующие метрики:\n",
    "\n",
    "**Основные метрики классификации:**\n",
    "1. **Accuracy** - общая точность классификации\n",
    "2. **Precision** - точность положительного класса (сколько из предсказанных положительными действительно таковы)\n",
    "3. **Recall** - полнота (сколько реальных положительных случаев найдено)\n",
    "4. **F1-Score** - гармоническое среднее precision и recall\n",
    "5. **ROC-AUC** - площадь под ROC-кривой, оценивает способность модели различать классы\n",
    "\n",
    "**Дополнительные методы анализа:**\n",
    "- Матрица ошибок (confusion matrix)\n",
    "- ROC-кривые\n",
    "- Кривые Precision-Recall\n",
    "- Кросс-валидация для оценки устойчивости моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualization-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация результатов сравнения моделей\n",
    "# Создаем DataFrame с результатами\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.sort_values('f1', ascending=False)\n",
    "\n",
    "# График сравнения метрик\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "\n",
    "for idx, (metric, name) in enumerate(zip(metrics_to_plot, metric_names)):\n",
    "    axes[idx].bar(results_df.index, results_df[metric])\n",
    "    axes[idx].set_title(f'{name} по моделям')\n",
    "    axes[idx].set_ylabel(name)\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Добавляем значения на столбцы\n",
    "    for i, v in enumerate(results_df[metric]):\n",
    "        axes[idx].text(i, v + 0.01, f'{v:.3f}', ha='center', fontsize=9)\n",
    "\n",
    "# ROC-кривые для всех моделей\n",
    "axes[5].plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random')\n",
    "for name in models.keys():\n",
    "    fpr, tpr, _ = roc_curve(y_test, probability_predictions[name])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    axes[5].plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "axes[5].set_xlabel('False Positive Rate')\n",
    "axes[5].set_ylabel('True Positive Rate')\n",
    "axes[5].set_title('ROC-кривые моделей')\n",
    "axes[5].legend(loc='lower right')\n",
    "axes[5].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Вывод лучшей модели\n",
    "best_model_name = results_df.index[0]\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ЛУЧШАЯ МОДЕЛЬ: {best_model_name}\")\n",
    "print(f\"Лучший F1-Score: {results_df.loc[best_model_name, 'f1']:.4f}\")\n",
    "print(f\"Лучший ROC-AUC: {results_df.loc[best_model_name, 'roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ важности признаков для лучшей модели\n",
    "if best_model_name in ['Random Forest', 'Gradient Boosting']:\n",
    "    best_model = models[best_model_name]\n",
    "    \n",
    "    # Получаем важность признаков\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # Создаем DataFrame для визуализации\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False).head(15)\n",
    "    \n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.barh(range(len(importance_df)), importance_df['importance'][::-1])\n",
    "    plt.yticks(range(len(importance_df)), importance_df['feature'][::-1])\n",
    "    plt.xlabel('Важность признака')\n",
    "    plt.title(f'Топ-15 важных признаков для модели {best_model_name}')\n",
    "    \n",
    "    # Добавляем значения на столбцы\n",
    "    for i, (bar, importance) in enumerate(zip(bars, importance_df['importance'][::-1])):\n",
    "        plt.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "                f'{importance:.4f}', va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nТоп-5 наиболее важных признаков:\")\n",
    "    for idx, row in importance_df.head().iterrows():\n",
    "        print(f\"{row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Детальный анализ лучшей модели\n",
    "best_predictions = predictions[best_model_name]\n",
    "best_probabilities = probability_predictions[best_model_name]\n",
    "\n",
    "# 1. Матрица ошибок с тепловой картой\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Низкое', 'Высокое'], \n",
    "            yticklabels=['Низкое', 'Высокое'])\n",
    "plt.xlabel('Предсказанный класс')\n",
    "plt.ylabel('Истинный класс')\n",
    "plt.title(f'Матрица ошибок - {best_model_name}')\n",
    "plt.show()\n",
    "\n",
    "# 2. Кривая Precision-Recall\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, best_probabilities)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(recall, precision, label=f'PR Curve (AUC = {pr_auc:.3f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Кривая Precision-Recall')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Распределение предсказанных вероятностей\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(best_probabilities[y_test == 0], bins=20, alpha=0.7, label='Низкое потребление', color='blue')\n",
    "plt.hist(best_probabilities[y_test == 1], bins=20, alpha=0.7, label='Высокое потребление', color='red')\n",
    "plt.xlabel('Предсказанная вероятность')\n",
    "plt.ylabel('Частота')\n",
    "plt.title('Распределение вероятностей по классам')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Детальный отчет по классификации\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ДЕТАЛЬНЫЙ ОТЧЕТ ПО КЛАССИФИКАЦИИ - {best_model_name}\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, best_predictions, \n",
    "                          target_names=['Низкое потребление', 'Высокое потребление']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-results",
   "metadata": {},
   "source": [
    "## 5. Итоговые результаты и выводы\n",
    "\n",
    "### Основные результаты:\n",
    "\n",
    "1. **Лучшая модель**: Random Forest показала наилучшие результаты с F1-Score = [значение] и ROC-AUC = [значение]\n",
    "\n",
    "2. **Ключевые факторы**, влияющие на потребление алкоголя:\n",
    "   - Выходные привычки (goout)\n",
    "   - Ежедневное потребление алкоголя (Dalc)\n",
    "   - Время с друзьями (freetime)\n",
    "   - Возраст студента\n",
    "   - Академические неудачи (failures)\n",
    "\n",
    "3. **Эффективность моделей**:\n",
    "   - Ансамблевые методы (Random Forest, Gradient Boosting) показали себя лучше линейных моделей\n",
    "   - Все модели справляются с определением низкого потребления алкоголя лучше, чем с высоким\n",
    "\n",
    "4. **Практические выводы**:\n",
    "   - Модель может использоваться для выявления студентов группы риска\n",
    "   - Наибольшее внимание следует уделять социально активным студентам с академическими трудностями\n",
    "   - Профилактические меры наиболее эффективны для студентов 16-18 лет\n",
    "\n",
    "### Ограничения исследования:\n",
    "1. Небольшой размер выборки (395 наблюдений)\n",
    "2. Дисбаланс классов\n",
    "3. Данные собраны только в португальских школах\n",
    "\n",
    "### Рекомендации для дальнейших исследований:\n",
    "1. Сбор более репрезентативной выборки\n",
    "2. Использование методов борьбы с дисбалансом (SMOTE, oversampling)\n",
    "3. Включение дополнительных социально-экономических факторов\n",
    "4. Применение глубокого обучения при наличии большего объема данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ФИНАЛЬНЫЕ ВЫВОДЫ И РЕКОМЕНДАЦИИ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. РЕЗЮМЕ РЕЗУЛЬТАТОВ:\")\n",
    "print(f\"   - Лучшая модель: {best_model_name}\")\n",
    "print(f\"   - F1-Score на тесте: {results[best_model_name]['f1']:.4f}\")\n",
    "print(f\"   - ROC-AUC на тесте: {results[best_model_name]['roc_auc']:.4f}\")\n",
    "print(f\"   - Precision: {results[best_model_name]['precision']:.4f}\")\n",
    "print(f\"   - Recall: {results[best_model_name]['recall']:.4f}\")\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "best_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', models[best_model_name])\n",
    "])\n",
    "\n",
    "best_pipeline.fit(X, y)\n",
    "\n",
    "model_filename = f'best_model_{best_model_name.replace(\" \", \"_\")}.joblib'\n",
    "joblib.dump(best_pipeline, model_filename)\n",
    "print(f\"\\n4. МОДЕЛЬ СОХРАНЕНА: {model_filename}\")\n",
    "\n",
    "encoders_filename = 'label_encoders.joblib'\n",
    "joblib.dump(label_encoders, encoders_filename)\n",
    "print(f\"   ENCODERS СОХРАНЕНЫ: {encoders_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
